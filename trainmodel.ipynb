{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "974fd3bf",
      "metadata": {},
      "source": [
        "## Learning Problem\n",
        "This project demonstrates training a model that gives relevance scores between the headline of an article and the paragraphs in the article. This is useful for summarizing articles and getting to the details you really want by effectively flagging paragraphs as relevant or irrelevant, or for helping filter out articles that are not very relevant to their headline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ce49f6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MiniLM fine-tuning with a pure PyTorch training loop\n",
        "# Keeps HF tokenizer/model for compatibility with ONNX export, but all training/eval is manual.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "DATA_PATH = Path(\"./data/annotated/merged_annotations.json\")\n",
        "OUTPUT_DIR = Path(\"fluff-model\")\n",
        "MODEL_NAME = \"microsoft/MiniLM-L12-H384-uncased\"\n",
        "MAX_LEN = 256\n",
        "EPOCHS = 5  # reduced to curb overfitting\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "EVAL_BATCH_SIZE = 32\n",
        "LR = 2e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_RATIO = 0.06\n",
        "LOG_INTERVAL = 50\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c47ef3",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ArticleDataset(Dataset):\n",
        "    def __init__(self, records: List[Dict[str, Any]]):\n",
        "        self.records = records\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rec = self.records[idx]\n",
        "        return (rec[\"headline\"], rec[\"text\"]), int(rec[\"label\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "593b4a89",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    with DATA_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        raw_records = json.load(f)\n",
        "\n",
        "    # Normalize to explicit fields we care about\n",
        "    records = []\n",
        "    for item in raw_records:\n",
        "        records.append(\n",
        "            {\n",
        "                \"headline\": item.get(\"headline\", \"\"),\n",
        "                \"text\": item.get(\"text\") or item.get(\"paragraph\") or \"\",\n",
        "                \"label\": int(item[\"label\"]),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    labels = [r[\"label\"] for r in records]\n",
        "    train_records, test_records = train_test_split(\n",
        "        records, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "    return list(train_records), list(test_records)\n",
        "\n",
        "\n",
        "def make_collate(tokenizer):\n",
        "    def collate(batch):\n",
        "        pairs, labels = zip(*batch)\n",
        "        headlines, texts = zip(*pairs)\n",
        "        enc = tokenizer(\n",
        "            list(headlines),\n",
        "            list(texts),\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return enc, torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return collate\n",
        "\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, scheduler, loss_fn, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for step, (enc, labels) in enumerate(dataloader, 1):\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**enc)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if step % LOG_INTERVAL == 0:\n",
        "            print(f\"  step {step:5d} | loss {loss.item():.4f}\")\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_labels, all_preds = [], []\n",
        "    total_loss = 0.0\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for enc, labels in dataloader:\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(**enc)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "    return {\"loss\": avg_loss, \"accuracy\": acc, \"f1\": f1}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364d6592",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_records, test_records = load_data()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)\n",
        "\n",
        "# Class weights\n",
        "y_train = np.array([r[\"label\"] for r in train_records])\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.array([0, 1]), y=y_train)\n",
        "weight_tensor = torch.tensor(class_weights, dtype=torch.float, device=device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=weight_tensor)\n",
        "\n",
        "# DataLoaders\n",
        "collate_fn = make_collate(tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    ArticleDataset(train_records),\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "eval_loader = DataLoader(\n",
        "    ArticleDataset(test_records),\n",
        "    batch_size=EVAL_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "warmup_steps = int(WARMUP_RATIO * total_steps)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "best_metrics = None\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"\n",
        "Epoch {epoch}/{EPOCHS}\")\n",
        "    train_loss = train_one_epoch(\n",
        "        model, train_loader, optimizer, scheduler, loss_fn, device\n",
        "    )\n",
        "    metrics = evaluate(model, eval_loader, device)\n",
        "\n",
        "    print(\n",
        "        f\"  train_loss={train_loss:.4f} | \"\n",
        "        f\"eval_loss={metrics['loss']:.4f} | \"\n",
        "        f\"acc={metrics['accuracy']:.4f} | \"\n",
        "        f\"f1={metrics['f1']:.4f}\"\n",
        "    )\n",
        "\n",
        "    if metrics[\"loss\"] < best_loss:\n",
        "        best_loss = metrics[\"loss\"]\n",
        "        best_metrics = metrics\n",
        "        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        model.save_pretrained(OUTPUT_DIR)\n",
        "        tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "        print(f\"  Saved new best model (eval_loss={best_loss:.4f})\")\n",
        "\n",
        "if best_metrics is None:\n",
        "    best_metrics = metrics\n",
        "\n",
        "results_path = OUTPUT_DIR / \"eval_results.json\"\n",
        "serializable = {k: float(v) for k, v in best_metrics.items()}\n",
        "with results_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(serializable, f, indent=2)\n",
        "\n",
        "print(f\"\n",
        "Saved metrics to {results_path}\")\n",
        "print(\"Model + tokenizer saved to ./fluff-model\")\n",
        "print(\n",
        "    \"Next: Run ONNX export with \"\n",
        "    \"`optimum-cli export onnx --model fluff-model --task text-classification --sequence_length 256 fluff-model-onnx`\"\n",
        ")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}